\begin{introduction}
Detection of the people and their subsequent identity preservation in a video sequence (tracking) is a part of a more broad task called \gls{mot}, which covers many different tasks. In the basic definition, \gls{mot} tries to estimate the position of the objects from multiple predefined classes, and then maintain their identity through the whole video sequence. Position estimation is done by a component known as the object detector, which predicts the bounding boxes with real-valued confidences of each object class in each video frame. However, the common object detector does not guarantee the relationship between objects in consecutive frames. Therefore, it is necessary to extract additional features from each object detected so the relationship in the sequence of frames can be built. The extracted features are mainly based on a visual appearance or movement of the object, but complementary information such as camera calibration and known scene parameters can also be incorporated. The subsequent tracking is then achieved by matching detected objects to preserved tracks based on various distance metrics that are calculated between features of the detected objects in a current frame and features of tracks from previous frames. One of the tracking benefits is that we can recover the trajectories of the objects that appeared in the video sequence, based on which we can calculate various spatial statistics that can help us to improve existing processes. Even though this work will focus only on the \gls{mot} task with person class, many principles apply to the general variant of \gls{mot} with multiple classes.

\section{Motivation}
    \gls{mot} is one of the essential and popular topics in the computer vision field. A large number of surveillance cameras in use has led to strong demand for automatic methods of processing their outputs. The scientific challenge in crowd image analysis is to devise and implement methods for obtaining detailed information about the number, density, movements, and actions involving people observed by a single camera or by a network of cameras.  
    
    Historically, the progress in this field has been limited by the number and size of the available datasets, and it was especially challenging to make comparisons between algorithms if they have been tested on different datasets under widely varying conditions. Thus, the needs of the researchers eventually formed the very first and most known PETS2009 \cite{ferryman2009pets2009} person tracking dataset. However, this dataset is minimal. There are only three sequences related to person tracking with ground-truth information, and performance evaluation metrics were often applied inconsistently, for example involving using different subsets of the available data, different ways of training the models, or differing evaluation scripts. The big break came in the year 2015 when MOTChallenge \cite{MOTChallenge2015} was released with the goal of standardization of quantitative benchmark to address such issues for \gls{mot} field. Not only did they create unified evaluation framework with standardized metrics, but they also created the large-scale dataset with a total of 22 sequences, half for training and a half for testing, with a total of 11286 frames or 996 seconds of video. The MOTChallenge \cite{MOTChallenge2015} benchmark has massively transformed the \gls{mot} field which resulted in serious improvements to existing \gls{mot} algorithms. Its popularity can also be expressed in numbers; for example, 99 \gls{mot} tracking algorithms were submitted to the MOT17 challenge \cite{mot16} during the year 2017 and similarly previous years. 
    
    Since the accuracy of existing algorithms is increasing and the price of \gls{gpu} computations is decreasing, new and more challenging datasets are being invented. VisDrone2018 \cite{zhuvisdrone2018} is a current state-of-the-art \gls{mot} dataset with over 260 video clips and more than 2.5 million bounding boxes of various class objects annotated. The frames are captured by several drone-mounted cameras which causes an unusual perspective and makes the dataset even more challenging. To this day, there are more than ten large-scale \gls{mot} benchmarks publicly available which demonstrates that this task problem, especially with objects such as people, vehicles, and bicycles, has enormous attention in the research community and there is a still room for improvement. 
    
    The logical extension beyond detection and tracking horizons is the extraction of additional class-specific features. If we would track cars, we could take advantage of estimation of car paint, brand, and type. This information can then be used for various temporal and regional statistics - for example, for estimating the richness of a town by counting luxury-type cars. If we take another case, which is the extraction of class-specific features about the people, we might be interested in the estimation of race, gender, height, mood, hair color, and clothes color. These traits are called soft biometrics, and they are mostly used in cases where we need to complement primary biometric identifiers, such as fingerprint, palm veins, iris pattern, to provide authentication based on the unique identification of the person. The estimation of class-specific features is noisy. Therefore it is essential to have accurate \gls{mot} algorithm, so the features are not collected from a single frame, but appropriately calculated from the whole tracking session.
    
    Although soft biometric characteristics lack the distinctiveness and permanence to recognize an individual uniquely and reliably, and can be easily faked, they provide some evidence about the people identity that could be beneficial. With the use of soft biometrics, we can differentiate individuals in surveillance video where it is very common that people are often occluded. In other words, despite the fact they are unable to individualize a subject, they are effective in distinguishing between people, thus maintaining people's identity in a surveillance scene. Another useful utilization is in the retail environment where we can build aggregated statistics such as the number of women between age 25 and 40 visited our store in the morning. If we have information that in the morning there is 75 \% women of visitors, we could utilize this and adapt the store to be more suitable for women, and therefore we will have a better chance to increase profit.
    
    Last but not least, having an accurate and flawless \gls{MOT} framework is crucial for further expansion to popular \gls{mtmct} field, which is the problem of determining who is where at all times given a set of video streams as input. The output is a set of person trajectories. Person \gls{reid} is a closely related problem. Given a query image of a person, the goal is to retrieve from a database of images taken by different cameras the images where the same person appears. \cite{ristani2016MTMC}
    
\section{Challenges}
\section{Thesis goals}
    The aim of this thesis to design and implement a framework that could utilize surveillance sequences and extract as much information as possible about the people in the scene.
    Such a framework could be used in many applications in the retail environment, for example, we can use it is a commercial store where is the high demand for learning a customer trends in specific days and hours, which could be easily achieved by collecting customer information such as age, gender, mood, etc. Other scenarios could be with a personalized advertisement, targeted at passers-by in a shopping center or real-time alert of store employees when a senior enters the store, so they can immediately offer an assistance. And lastly, we could use this framework to distinguish between customers and employees so we can analyze their interaction or even go further and optimize the distribution of employees around the store.
  
\section{Thesis structure}
    The rest of this thesis is organized as follows. In the first chapter, we present existing methods which are crucial for understanding of this task. Chapter 2 is devoted to analysis with proposals how the thesis assignment can be solved. Design of the algorithms is done in chapter 3. Implementation details are explained in the chapter 4, followed by the evaluation presented in chapter 5. The latest is a summary of all the findings and suggestions for future improvements.
    
\end{introduction}